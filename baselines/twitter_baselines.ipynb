{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing Python Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import mysql.connector\n",
    "from datetime import datetime as dt\n",
    "import matplotlib\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Importing the Data Sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Twitter Data:\n",
    "twitter_df = pd.read_csv(\"../data/local_data/twitter/twitter.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importing Industry Categories Table:\n",
    "industries_df = pd.read_csv(\"../data/local_data/stocks/csv/industries.csv\")\n",
    "companies_df = pd.read_csv(\"../data/list_of_companies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Stock Price Data:\n",
    "\n",
    "stocks_df = pd.read_csv(\"../data/local_data/stocks/csv/stock_prices.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating the Labeled Training Data Set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the Stock Price data frame:\n",
    "\n",
    "company_ids = twitter_df.company_id.unique()\n",
    "stocks_df = stocks_df[stocks_df.company_id.isin(company_ids)].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the date columns to Unix Epoch Time:\n",
    "\n",
    "twitter_df[\"date\"] = pd.to_datetime(twitter_df[\"date\"]).values.astype(np.int64) // 10**6\n",
    "twitter_df[\"date\"] = (twitter_df[\"date\"])//1000\n",
    "\n",
    "stocks_df[\"date\"] = pd.to_datetime(stocks_df[\"date\"]).values.astype(np.int64) // 10**6\n",
    "stocks_df[\"date\"] = (stocks_df[\"date\"] + 57600000)//1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining the date range for both data sets:\n",
    "\n",
    "twitter_min_dates = twitter_df.groupby([\"company_id\"]).date.min()\n",
    "twitter_max_dates = twitter_df.groupby([\"company_id\"]).date.max()\n",
    "\n",
    "stocks_min_dates = stocks_df.groupby([\"company_id\"]).date.min()\n",
    "stocks_max_dates = stocks_df.groupby([\"company_id\"]).date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing the datasets based on the min/max dates: \n",
    "\n",
    "for id in company_ids:\n",
    "    stocks_df = stocks_df.drop(stocks_df[((stocks_df[\"company_id\"] == id) & (stocks_df[\"date\"] < (twitter_min_dates[id] + 86400)))].index)\n",
    "    stocks_df = stocks_df.drop(stocks_df[((stocks_df[\"company_id\"] == id) & (stocks_df[\"date\"] > (twitter_max_dates[id] - 86400)))].index)\n",
    "    twitter_df = twitter_df.drop(twitter_df[((twitter_df[\"company_id\"] == id) & (twitter_df[\"date\"] < (stocks_min_dates[id] - 86400)))].index)\n",
    "    twitter_df = twitter_df.drop(twitter_df[((twitter_df[\"company_id\"] == id) & (twitter_df[\"date\"] > (stocks_max_dates[id] + 86400)))].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "24\n",
      "21\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "41\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "117\n",
      "68\n",
      "69\n",
      "122\n",
      "71\n",
      "72\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "\n",
    "for id in company_ids:\n",
    "    print(id)\n",
    "    this_stock = stocks_df[stocks_df[\"company_id\"] == id]\n",
    "    this_twitter = twitter_df[twitter_df[\"company_id\"] == id]\n",
    "    this_ind_id = this_twitter[\"industry_id\"].iloc[0]\n",
    "    for index, row in this_stock.iterrows():\n",
    "        end = row.date\n",
    "        start = end - 86400\n",
    "        day_twitter = twitter_df[(twitter_df[\"date\"] >= start) & (twitter_df[\"date\"] <= end)].mean()\n",
    "        human_date = dt.fromtimestamp(row.date).strftime('%Y-%m-%d %H:%M:%S').split(\" \")[0]\n",
    "        rows.append({\n",
    "            \"company_id\": row.company_id,\n",
    "            \"industry_id\": this_ind_id,\n",
    "            \"date\": human_date,\n",
    "            \"overall\": day_twitter.overall_sentiment,\n",
    "            \"positive\": day_twitter.positive_sentiment,\n",
    "            \"negative\": day_twitter.negative_sentiment,\n",
    "            \"neutral\": day_twitter.neutral_sentiment,\n",
    "            \"change_percent\": row.change_percent\n",
    "        }) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.DataFrame.from_dict(rows, orient='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_id</th>\n",
       "      <th>industry_id</th>\n",
       "      <th>date</th>\n",
       "      <th>overall</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>change_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-01-17</td>\n",
       "      <td>0.192433</td>\n",
       "      <td>0.140295</td>\n",
       "      <td>0.040446</td>\n",
       "      <td>0.819267</td>\n",
       "      <td>-2.0636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-01-18</td>\n",
       "      <td>0.164156</td>\n",
       "      <td>0.133215</td>\n",
       "      <td>0.047739</td>\n",
       "      <td>0.819035</td>\n",
       "      <td>1.4047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-01-19</td>\n",
       "      <td>0.158477</td>\n",
       "      <td>0.130572</td>\n",
       "      <td>0.048721</td>\n",
       "      <td>0.820712</td>\n",
       "      <td>-1.9697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-01-20</td>\n",
       "      <td>0.172023</td>\n",
       "      <td>0.136606</td>\n",
       "      <td>0.045839</td>\n",
       "      <td>0.817556</td>\n",
       "      <td>0.2870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-01-23</td>\n",
       "      <td>0.154186</td>\n",
       "      <td>0.134041</td>\n",
       "      <td>0.051439</td>\n",
       "      <td>0.814524</td>\n",
       "      <td>-0.0440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37175</th>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-02-27</td>\n",
       "      <td>0.196590</td>\n",
       "      <td>0.118910</td>\n",
       "      <td>0.051424</td>\n",
       "      <td>0.829673</td>\n",
       "      <td>-4.8972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37176</th>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-02-28</td>\n",
       "      <td>0.216627</td>\n",
       "      <td>0.130245</td>\n",
       "      <td>0.049570</td>\n",
       "      <td>0.820192</td>\n",
       "      <td>-2.1627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37177</th>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-03-02</td>\n",
       "      <td>0.207522</td>\n",
       "      <td>0.119663</td>\n",
       "      <td>0.048932</td>\n",
       "      <td>0.831396</td>\n",
       "      <td>3.0526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37178</th>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-03-03</td>\n",
       "      <td>0.207606</td>\n",
       "      <td>0.119507</td>\n",
       "      <td>0.048603</td>\n",
       "      <td>0.831879</td>\n",
       "      <td>-5.5158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37179</th>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-03-04</td>\n",
       "      <td>0.200984</td>\n",
       "      <td>0.120966</td>\n",
       "      <td>0.053682</td>\n",
       "      <td>0.825339</td>\n",
       "      <td>2.3063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37180 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       company_id  industry_id        date   overall  positive  negative  \\\n",
       "0              23            3  2017-01-17  0.192433  0.140295  0.040446   \n",
       "1              23            3  2017-01-18  0.164156  0.133215  0.047739   \n",
       "2              23            3  2017-01-19  0.158477  0.130572  0.048721   \n",
       "3              23            3  2017-01-20  0.172023  0.136606  0.045839   \n",
       "4              23            3  2017-01-23  0.154186  0.134041  0.051439   \n",
       "...           ...          ...         ...       ...       ...       ...   \n",
       "37175          20            3  2020-02-27  0.196590  0.118910  0.051424   \n",
       "37176          20            3  2020-02-28  0.216627  0.130245  0.049570   \n",
       "37177          20            3  2020-03-02  0.207522  0.119663  0.048932   \n",
       "37178          20            3  2020-03-03  0.207606  0.119507  0.048603   \n",
       "37179          20            3  2020-03-04  0.200984  0.120966  0.053682   \n",
       "\n",
       "        neutral  change_percent  \n",
       "0      0.819267         -2.0636  \n",
       "1      0.819035          1.4047  \n",
       "2      0.820712         -1.9697  \n",
       "3      0.817556          0.2870  \n",
       "4      0.814524         -0.0440  \n",
       "...         ...             ...  \n",
       "37175  0.829673         -4.8972  \n",
       "37176  0.820192         -2.1627  \n",
       "37177  0.831396          3.0526  \n",
       "37178  0.831879         -5.5158  \n",
       "37179  0.825339          2.3063  \n",
       "\n",
       "[37180 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the training data set to a csv file:\n",
    "\n",
    "training_data.to_csv(r'twitter_training_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Building the Baselines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting the data set into training and testing sets:\n",
    "\n",
    "X = training_data[[\"positive\", \"negative\", \"neutral\", \"change_percent\"]].dropna()\n",
    "y = X[\"change_percent\"]\n",
    "y2 = (X[\"change_percent\"] >= 0).astype(int)\n",
    "del X[\"change_percent\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y2, test_size=0.2, random_state=0)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y2, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Multi-linear Regression Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00033901626376764415"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building the logistic Model:\n",
    "\n",
    "lin_model = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "# Getting the model's R^2 score:\n",
    "\n",
    "score = lin_model.score(X_train, y_train)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2491552081821679"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the outputs for the Testing Data Set:\n",
    "\n",
    "y_pred = lin_model.predict(X_test)\n",
    "\n",
    "# Getting the Mean Squared Error (MSE):\n",
    "\n",
    "rmse_lin = mse(y_test,y_pred, squared=True)\n",
    "rmse_lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-134-5f57d3162fc3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Calculating the F1-score:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mf1_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'micro'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mf1_s\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1097\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1098\u001b[0m                        \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1099\u001b[1;33m                        zero_division=zero_division)\n\u001b[0m\u001b[0;32m   1100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1224\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'f-score'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1225\u001b[0m                                                  \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1226\u001b[1;33m                                                  zero_division=zero_division)\n\u001b[0m\u001b[0;32m   1227\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1482\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1483\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[1;32m-> 1484\u001b[1;33m                                     pos_label)\n\u001b[0m\u001b[0;32m   1485\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1486\u001b[0m     \u001b[1;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1299\u001b[0m                          str(average_options))\n\u001b[0;32m   1300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1301\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1302\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1303\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maverage\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'binary'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[1;32m---> 90\u001b[1;33m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "# Calculating the F1-score:\n",
    "\n",
    "f1_s = f1_score(y_test, y_pred, average='micro')\n",
    "f1_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Logistic Regression Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the logistic Model Using 10-fold Cross Validation:\n",
    "\n",
    "log_model = LogisticRegressionCV(cv=10, random_state=0).fit(X_train2, y_train2)\n",
    "\n",
    "# Predicting the outputs for the Testing Data Set:\n",
    "\n",
    "y_pred2 = log_model.predict(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5319435104236718"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating the F1-score:\n",
    "\n",
    "f1_s = f1_score(y_test2, y_pred2, average='micro')\n",
    "f1_s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
