{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The cell below loads all data. Make sure your filepaths are updated to work on your computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df = pd.read_csv('../data/reddit_text_sentiment.csv')\n",
    "stocks_df = pd.read_csv(\"../data/stock_prices.csv\")\n",
    "companies_df = pd.read_csv(\"../data/companies.csv\")\n",
    "brands_df = pd.read_csv(\"../data/brands.csv\")\n",
    "industries_df = pd.read_csv(\"../data/industries.csv\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Below three cells add the 'datetime' column to stocks_df and reddit_df. This column contains datetime format object of stock market closing time (EST)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function to convert utc to EST date\n",
    "eastern = timezone('US/Eastern')\n",
    "def utc_to_est(utc):\n",
    "    return datetime.fromtimestamp(utc, tz = eastern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new stocks column with datetime format of daily market close times\n",
    "stocks_df[\"date\"] = pd.to_datetime(stocks_df[\"date\"]).values.astype(np.int64) // 10**6\n",
    "stocks_df[\"date\"] = (stocks_df[\"date\"] + 57600000)//1000\n",
    "stocks_df['datetime'] = stocks_df['date'].apply(utc_to_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#created new reddit column with datetime format of daily market close times\n",
    "reddit_df['datetime'] = reddit_df['created_utc'].apply(utc_to_est)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Following cell does some basic manipulation for the reddit_df:\n",
    "1. select the columns that I will be using (save space and time)\n",
    "2. add tally to posts so that I can get average weighted sentiment scores later\n",
    "3. convert nonzero scores to something trivial\n",
    "4. create weighted_scores column\n",
    "5. add column for company_id by merging with brands_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select relevant columns\n",
    "reddit_df = reddit_df[['subreddit', 'datetime', 'score', 'compound', 'positive', 'neutral', 'negative']]\n",
    "\n",
    "#add column that helps in counting posts when grouped\n",
    "reddit_df['num_posts'] = 1\n",
    "reddit_df['positive_posts'] = reddit_df['compound'] > 0.3\n",
    "reddit_df['negative_posts'] = reddit_df['compound'] < -0.3\n",
    "\n",
    "#replace zeros with insubstatial float in reddit scores\n",
    "reddit_df.score = reddit_df.score.apply(lambda x: max(x, 0.01))\n",
    "\n",
    "#weighted scores\n",
    "for s in ['compound', 'negative', 'positive', 'neutral']:\n",
    "    reddit_df['weighted_{0}'.format(s)] = reddit_df[s]*reddit_df['score'].apply(lambda x: math.log(x+1))\n",
    "    \n",
    "#add company_id as column\n",
    "reddit_df = reddit_df.merge(brands_df[['subreddit', 'company_id']], on='subreddit')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Following cells are helper functions:\n",
    "\n",
    "1. separate_reddit takes in the full reddit dataframe and outputs a list of sub-dataframes that are separated either by company, industry, or not at all. The 'by' argument must be one of 'company', 'industry', or 'all'.\n",
    "\n",
    "2. group_data function is meant to be applied to every dataframe output in the separate_reddit output list. This function takes df, by, and days as arguments. 'df' should be a dataframe obtained from the separate_reddit function. 'by' should be one of the strings allowed by the separate_reddit function 'by' argument. 'days' should be an integer. The function outputs a dataframe with datetime (on the later end of each group), weighted sentiment scores (summed over the rolling window), and the company_id or industry_id (if by=='industry')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function that takes a dataframe and returns separate dataframes for each company\n",
    "def separate_reddit(reddit_df, by='all'):\n",
    "    if by not in ['all', 'company', 'industry']:\n",
    "        print('argument invalid: must be = <all>, <company>, or <industry>')\n",
    "        pass\n",
    "    else:\n",
    "        if by == 'industry':\n",
    "            temp = reddit_df.merge(companies_df[['id', 'industry_id']], left_on = 'company_id', right_on='id')\n",
    "            return [temp[temp['industry_id']==i][['industry_id', 'datetime','weighted_compound', 'weighted_negative', 'weighted_positive', 'weighted_neutral', 'num_posts', 'positive_posts', 'negative_posts']] for i in temp.industry_id.unique()]\n",
    "        elif by == 'company':\n",
    "            return [reddit_df[reddit_df['company_id']==i][['company_id', 'datetime','weighted_compound', 'weighted_negative', 'weighted_positive', 'weighted_neutral', 'num_posts', 'positive_posts', 'negative_posts']] for i in reddit_df.company_id.unique()]\n",
    "        else:\n",
    "            return [reddit_df[['company_id', 'datetime','weighted_compound', 'weighted_negative', 'weighted_positive', 'weighted_neutral', 'num_posts', 'positive_posts', 'negative_posts']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#groups data for a single company using sliding window - number of days specified in call\n",
    "def group_data(df, by='all', days = 1):\n",
    "    if by not in ['all', 'company', 'industry']:\n",
    "        print('invalid arg: must be in [all, company, industry]')\n",
    "        pass\n",
    "    else:\n",
    "        if by=='industry':\n",
    "            i_id = df.industry_id.unique()[0] #save industry_id\n",
    "            temp_df = df[['datetime', 'weighted_compound', 'weighted_positive', 'weighted_neutral', 'weighted_negative', 'num_posts', 'positive_posts', 'negative_posts']].groupby(pd.Grouper(key='datetime', freq='24h', base=11, label='right')).sum() #groupby day\n",
    "            min_date = min(temp_df.index)\n",
    "            max_date = max(temp_df.index)\n",
    "            date_idx = [i for i in pd.date_range(min_date, max_date)] #new index\n",
    "            temp_df = temp_df.reindex(date_idx).fillna(0).rolling(days).sum()[days-1:] #make dataframe with rolling window sum\n",
    "            temp_df['industry_id'] = i_id #restore industry_id\n",
    "            temp_df.reset_index(inplace=True)\n",
    "            return temp_df\n",
    "        elif by=='company':\n",
    "            c_id = df.company_id.unique()[0] #save company_id\n",
    "            temp_df = df[['datetime', 'weighted_compound', 'weighted_positive', 'weighted_neutral', 'weighted_negative', 'num_posts', 'positive_posts', 'negative_posts']].groupby(pd.Grouper(key='datetime', freq='24h', base=11, label='right')).sum() #groupby day\n",
    "            min_date = min(temp_df.index)\n",
    "            max_date = max(temp_df.index)\n",
    "            date_idx = [i for i in pd.date_range(min_date, max_date)] #new index\n",
    "            temp_df = temp_df.reindex(date_idx).fillna(0).rolling(days).sum()[days-1:] #make dataframe with rolling window sum\n",
    "            temp_df['company_id'] = c_id #restore company_id\n",
    "            temp_df.reset_index(inplace=True)\n",
    "            return temp_df\n",
    "        else:\n",
    "            return pd.concat([group_data(d, 'company', days) for d in separate_reddit(df, 'company')])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Following cell makes all of the dataframes ready for regression. Separates a given datafram, runs the group_data function on every one of them, calculates average weighted sentiment scores, and adds change percent to each dataframe. Outpust a list of dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataframes(df, separation='all', lookback=1, min_date = None, max_date = None):\n",
    "    if min_date:\n",
    "        df = df[df['datetime'] >= pd.to_datetime(min_date).tz_localize('US/Eastern')]\n",
    "    if max_date:\n",
    "        df = df[df['datetime'] <= pd.to_datetime(max_date).tz_localize('US/Eastern')]\n",
    "    dfs = []\n",
    "    separated = separate_reddit(df, separation)\n",
    "    for d in separated:\n",
    "        temp = group_data(d, separation, lookback)\n",
    "        for i in ['weighted_compound', 'weighted_negative', 'weighted_positive', 'weighted_neutral', 'positive_posts', 'negative_posts']: #iterate over scores columns\n",
    "            temp['avg_{}'.format(i)] = temp[i]/temp['num_posts'].apply(lambda x: max(x, 1)) #set avgerage weighted scores columns\n",
    "        temp = temp.merge(stocks_df[['company_id', 'datetime', 'change_percent']], on=['company_id', 'datetime']) #add change_percent column\n",
    "        dfs.append(temp)\n",
    "    return dfs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "For overall models (i.e. for all companies' data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function that finds optimal C for a given training set (logistic regression)\n",
    "def cross_validate_logreg(X_train, y_train, c_s = [0.1, 0.3, 1, 3, 10, 30, 100]):\n",
    "    c_s = [0.1, 0.3, 1, 3, 10, 30, 100]\n",
    "    lg_cv = LogisticRegressionCV(Cs = c_s, scoring='f1').fit(X_train, y_train)\n",
    "    return c_s[np.argmax(np.mean(lg_cv.scores_[True],axis=0))], np.max(np.mean(lg_cv.scores_[True], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg_by_lookback(reddit_df, lookback = [1], c_s = [0.1, 0.3, 1, 3, 10, 30, 100]):\n",
    "    for i in lookback:\n",
    "        full_df = make_dataframes(reddit_df, lookback = i, min_date = '2014-03-01')[0]\n",
    "        X = full_df[['avg_weighted_compound', 'avg_weighted_positive', 'avg_weighted_negative', 'avg_weighted_neutral', 'num_posts', 'avg_positive_posts', 'avg_negative_posts']]\n",
    "        y = full_df['change_percent'] > 0\n",
    "        X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state = 6240)\n",
    "        best_c, f1_score = cross_validate_logreg(X_train, y_train, c_s)\n",
    "        print('Best f1_score = {0} for {1} day lookback with C = {2}'.format(f1_score, i, best_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best f1_score = 0.6837936312061542 for 1 day lookback with C = 0.1\n",
      "Best f1_score = 0.6847001390207956 for 3 day lookback with C = 0.1\n",
      "Best f1_score = 0.6821921219983137 for 6 day lookback with C = 0.1\n",
      "Best f1_score = 0.6840706556579365 for 10 day lookback with C = 0.1\n",
      "Best f1_score = 0.6854336111299288 for 15 day lookback with C = 0.3\n"
     ]
    }
   ],
   "source": [
    "logreg_by_lookback(reddit_df, lookback = [1, 3, 6, 10, 15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.6860539163659521, precision: 1.0, recall: 0.5221324717285946, accuracy: 0.5221324717285946\n"
     ]
    }
   ],
   "source": [
    "#test out best logistic regression model\n",
    "full_df = make_dataframes(reddit_df, lookback = 15, min_date = '2014-03-01')[0]\n",
    "X = full_df[['avg_weighted_compound', 'avg_weighted_positive', 'avg_weighted_negative', 'avg_weighted_neutral', 'num_posts']]\n",
    "y = full_df['change_percent'] > 0\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.25, random_state = 6240)\n",
    "lg = LogisticRegression(C=0.3).fit(X_train, y_train)\n",
    "lg_preds = lg.predict(X_test)\n",
    "f1 = f1_score(lg_preds, y_test)\n",
    "precision = precision_score(lg_preds, y_test)\n",
    "recall = recall_score(lg_preds, y_test)\n",
    "accuracy = accuracy_score(lg_preds, y_test)\n",
    "print('f1: {0}, precision: {1}, recall: {2}, accuracy: {3}'.format(f1, precision, recall, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 day lookup:\n",
      "f1: 0.6690469651194727, precision: 0.9354838709677419, recall: 0.5207353569901667, accuracy: 0.5166466105094264\n",
      "3 day lookup:\n",
      "f1: 0.6810666666666667, precision: 0.9762996941896025, recall: 0.5229320229320229, accuracy: 0.5200642054574639\n",
      "6 day lookup:\n",
      "f1: 0.6049423393739704, precision: 0.6902255639097744, recall: 0.5384164222873901, accuracy: 0.5171163914619412\n",
      "10 day lookup:\n",
      "f1: 0.6879014989293363, precision: 0.9801678108314263, recall: 0.5298969072164949, accuracy: 0.5292692773516351\n",
      "15 day lookup:\n",
      "f1: 0.6773579777113345, precision: 0.9614197530864198, recall: 0.5228703315148971, accuracy: 0.5205977382875606\n"
     ]
    }
   ],
   "source": [
    "##Baseline tests for linear regression\n",
    "lookback_days = [1, 3, 6, 10, 15]\n",
    "for i in lookback_days:\n",
    "    full_df = make_dataframes(reddit_df, lookback = i, min_date = '2014-03-01')[0]\n",
    "    X = full_df[['avg_weighted_compound', 'avg_weighted_positive', 'avg_weighted_negative', 'avg_weighted_neutral', 'num_posts']]\n",
    "    y = full_df['change_percent']\n",
    "    X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state = 6240)\n",
    "    ln = LinearRegression(normalize=True).fit(X_train, y_train)\n",
    "    ln_pred = ln.predict(X_test)\n",
    "    ln_f1 = f1_score((ln_pred > 0), y_test >0)\n",
    "    ln_precision = precision_score((ln_pred > 0), y_test>0)\n",
    "    ln_recall  = recall_score(ln_pred>0, y_test>0)\n",
    "    ln_accuracy = accuracy_score(ln_pred>0, y_test>0)\n",
    "    print('{0} day lookup:'.format(i))\n",
    "    print('f1: {0}, precision: {1}, recall: {2}, accuracy: {3}'.format(ln_f1, ln_precision, ln_recall, ln_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 day lookback:\n",
      "f1: 0.595617529880478, precision: 0.6889400921658986, recall: 0.5245614035087719, accuracy: 0.5114320096269555\n",
      "3 day lookback:\n",
      "f1: 0.5839172505839173, precision: 0.668960244648318, recall: 0.5180580224985198, accuracy: 0.4995987158908507\n",
      "6 day lookback:\n",
      "f1: 0.5924439986626547, precision: 0.6661654135338346, recall: 0.5334136062612884, accuracy: 0.509061619009263\n",
      "10 day lookback:\n",
      "f1: 0.5748138117806364, precision: 0.6475972540045767, recall: 0.516737674984784, accuracy: 0.4929350020185709\n",
      "15 day lookback:\n",
      "f1: 0.5751189666893269, precision: 0.6527777777777778, recall: 0.5139732685297691, accuracy: 0.49515347334410337\n",
      "21 day lookback:\n",
      "f1: 0.5778546712802767, precision: 0.647788983708301, recall: 0.5215490318550906, accuracy: 0.5072697899838449\n",
      "28 day lookback:\n",
      "f1: 0.5765199161425576, precision: 0.6400310318076028, recall: 0.5244755244755245, accuracy: 0.5105008077544426\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "lookback_days = [1, 3, 6, 10, 15, 21, 28]\n",
    "for i in lookback_days:\n",
    "    full_df = make_dataframes(reddit_df, lookback = i, min_date = '2014-03-01')[0]\n",
    "    X = full_df[['avg_weighted_compound', 'avg_weighted_positive', 'avg_weighted_negative', 'avg_weighted_neutral', 'num_posts']]\n",
    "    y = full_df['change_percent'] > 0\n",
    "    X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state = 6240)\n",
    "    rf = RandomForestClassifier(n_estimators =100)\n",
    "    rf.fit(X_train, y_train)\n",
    "    preds = rf.predict(X_test)\n",
    "    f1 = f1_score(preds, y_test)\n",
    "    precision = precision_score(preds, y_test)\n",
    "    recall = recall_score(preds, y_test)\n",
    "    accuracy = accuracy_score(preds, y_test)\n",
    "    print('{0} day lookback:'.format(i))\n",
    "    print('f1: {0}, precision: {1}, recall: {2}, accuracy: {3}'.format(f1, precision, recall, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 day lookback:\n",
      "f1: 0.6773579777113345, precision: 0.9614197530864198, recall: 0.5228703315148971, accuracy: 0.5205977382875606\n",
      "3 day lookback:\n",
      "f1: 0.6773579777113345, precision: 0.9614197530864198, recall: 0.5228703315148971, accuracy: 0.5205977382875606\n",
      "6 day lookback:\n",
      "f1: 0.6773579777113345, precision: 0.9614197530864198, recall: 0.5228703315148971, accuracy: 0.5205977382875606\n",
      "10 day lookback:\n",
      "f1: 0.6773579777113345, precision: 0.9614197530864198, recall: 0.5228703315148971, accuracy: 0.5205977382875606\n",
      "15 day lookback:\n",
      "f1: 0.6773579777113345, precision: 0.9614197530864198, recall: 0.5228703315148971, accuracy: 0.5205977382875606\n"
     ]
    }
   ],
   "source": [
    "#XG Boost\n",
    "lookback_days = [1, 3, 6, 10, 15]\n",
    "for i in lookback_days:\n",
    "    full_df = make_dataframes(reddit_df, lookback = i, min_date = '2014-03-01')[0]\n",
    "    X = full_df[['avg_weighted_compound', 'avg_weighted_positive', 'avg_weighted_negative', 'avg_weighted_neutral', 'num_posts']]\n",
    "    y = full_df['change_percent'] > 0\n",
    "    X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state = 6240)\n",
    "    xg = GradientBoostingClassifier()\n",
    "    xg.fit(X_train, y_train)\n",
    "    preds = xg.predict(X_test)\n",
    "    f1 = f1_score(preds, y_test)\n",
    "    precision = precision_score(preds, y_test)\n",
    "    recall = recall_score(preds, y_test)\n",
    "    accuracy = accuracy_score(preds, y_test)\n",
    "    print('{0} day lookback:'.format(i))\n",
    "    print('f1: {0}, precision: {1}, recall: {2}, accuracy: {3}'.format(ln_f1, ln_precision, ln_recall, ln_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reddit_df.company_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall scores: f1:0.5384615384615384, precision: 0.5535535535535535, recall:0.524170616113744, accuracy0.4960127591706539\n"
     ]
    }
   ],
   "source": [
    "#create array of evaluation metrics by company with random forest\n",
    "rf_company_results = np.zeros((30, 5))\n",
    "full_df = make_dataframes(reddit_df, lookback = 28, min_date = '2014-03-01')[0]\n",
    "full_df = full_df[full_df.num_posts >0]\n",
    "X = full_df[['avg_weighted_compound', 'avg_weighted_positive', 'avg_weighted_negative', 'avg_weighted_neutral', 'num_posts', 'avg_positive_posts', 'avg_negative_posts']]\n",
    "y = full_df['change_percent'] > 0\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state = 6240)\n",
    "rf = RandomForestClassifier(n_estimators =100)\n",
    "rf.fit(X_train, y_train)\n",
    "preds = rf.predict(X_test)\n",
    "f1 = f1_score(preds, y_test)\n",
    "precision = precision_score(preds, y_test)\n",
    "recall = recall_score(preds, y_test)\n",
    "accuracy = accuracy_score(preds, y_test)\n",
    "dfs = make_dataframes(reddit_df, 'company', lookback = i, min_date = '2014-03-01')\n",
    "print('overall scores: f1:{0}, precision: {1}, recall:{2}, accuracy{3}'.format(f1, precision, recall, accuracy))\n",
    "i = 0\n",
    "for df in dfs:\n",
    "    c_id = df.company_id[0]\n",
    "    X = df[['avg_weighted_compound', 'avg_weighted_positive', 'avg_weighted_negative', 'avg_weighted_neutral', 'num_posts', 'avg_positive_posts', 'avg_negative_posts']]\n",
    "    y = df['change_percent'] > 0\n",
    "    preds = rf.predict(X)\n",
    "    f1 = f1_score(preds, y)\n",
    "    precision = precision_score(preds, y)\n",
    "    recall = recall_score(preds, y)\n",
    "    accuracy = accuracy_score(preds, y)\n",
    "    rf_company_results[i,] = [c_id, f1, precision, recall, accuracy]\n",
    "    i+=1\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>company_id</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Microsoft Corporation</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.669246</td>\n",
       "      <td>0.647940</td>\n",
       "      <td>0.692000</td>\n",
       "      <td>0.666016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.706320</td>\n",
       "      <td>0.698529</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.691406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazon.com, Inc.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.726944</td>\n",
       "      <td>0.723022</td>\n",
       "      <td>0.730909</td>\n",
       "      <td>0.705078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Facebook, Inc.</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.715867</td>\n",
       "      <td>0.721190</td>\n",
       "      <td>0.710623</td>\n",
       "      <td>0.699219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alphabet Inc</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.678700</td>\n",
       "      <td>0.681159</td>\n",
       "      <td>0.676259</td>\n",
       "      <td>0.652344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>eBay Inc.</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.736059</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.714801</td>\n",
       "      <td>0.722656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Twitter, Inc.</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.697030</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.706827</td>\n",
       "      <td>0.701172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HP Inc.</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.668501</td>\n",
       "      <td>0.920455</td>\n",
       "      <td>0.524838</td>\n",
       "      <td>0.529297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dell Technologies Inc.</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.743961</td>\n",
       "      <td>0.729970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Uber Technologies, Inc.</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.712644</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>0.720930</td>\n",
       "      <td>0.698795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Lyft, Inc.</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.658228</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.674699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Snap Inc.</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.773050</td>\n",
       "      <td>0.807407</td>\n",
       "      <td>0.741497</td>\n",
       "      <td>0.752896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Spotify Technology S.A.</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.744444</td>\n",
       "      <td>0.779070</td>\n",
       "      <td>0.712766</td>\n",
       "      <td>0.724551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AT&amp;T Inc.</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.747029</td>\n",
       "      <td>0.774648</td>\n",
       "      <td>0.721311</td>\n",
       "      <td>0.708984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>T-Mobile US Inc.</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.761745</td>\n",
       "      <td>0.785467</td>\n",
       "      <td>0.739414</td>\n",
       "      <td>0.722656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Sprint Corporation</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.694387</td>\n",
       "      <td>0.710638</td>\n",
       "      <td>0.678862</td>\n",
       "      <td>0.712891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Verizon Communications Inc.</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.670412</td>\n",
       "      <td>0.670412</td>\n",
       "      <td>0.670412</td>\n",
       "      <td>0.656250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>JPMorgan Chase &amp; Co.</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.696104</td>\n",
       "      <td>0.978102</td>\n",
       "      <td>0.540323</td>\n",
       "      <td>0.542969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Citigroup Inc.</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.658635</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.496970</td>\n",
       "      <td>0.501953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Bank of America</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.668740</td>\n",
       "      <td>0.964126</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0.520270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Wells Fargo &amp; Company</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.696721</td>\n",
       "      <td>0.934066</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.564706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PayPal Holdings, Inc.</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.744283</td>\n",
       "      <td>0.778261</td>\n",
       "      <td>0.713147</td>\n",
       "      <td>0.711944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>The American Express Company</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.689560</td>\n",
       "      <td>0.909420</td>\n",
       "      <td>0.555310</td>\n",
       "      <td>0.558594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Capital One Financial Corporation</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.682422</td>\n",
       "      <td>0.885057</td>\n",
       "      <td>0.555288</td>\n",
       "      <td>0.580078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Netflix, Inc.</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.721612</td>\n",
       "      <td>0.740602</td>\n",
       "      <td>0.703571</td>\n",
       "      <td>0.703125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>DISH Network Corporation</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.657609</td>\n",
       "      <td>0.927203</td>\n",
       "      <td>0.509474</td>\n",
       "      <td>0.507812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Comcast Corporation</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.669131</td>\n",
       "      <td>0.660584</td>\n",
       "      <td>0.677903</td>\n",
       "      <td>0.650391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ViacomCBS Inc.</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.650104</td>\n",
       "      <td>0.630522</td>\n",
       "      <td>0.670940</td>\n",
       "      <td>0.669922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Fox Corporation</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.831325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Grubhub Inc.</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.759036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 name  company_id        f1  precision  \\\n",
       "0               Microsoft Corporation         1.0  0.669246   0.647940   \n",
       "1                          Apple Inc.         2.0  0.706320   0.698529   \n",
       "2                    Amazon.com, Inc.         3.0  0.726944   0.723022   \n",
       "3                      Facebook, Inc.         4.0  0.715867   0.721190   \n",
       "4                        Alphabet Inc         5.0  0.678700   0.681159   \n",
       "5                           eBay Inc.         6.0  0.736059   0.758621   \n",
       "6                       Twitter, Inc.         7.0  0.697030   0.687500   \n",
       "7                             HP Inc.         8.0  0.668501   0.920455   \n",
       "8              Dell Technologies Inc.         9.0  0.771930   0.802083   \n",
       "9             Uber Technologies, Inc.        10.0  0.712644   0.704545   \n",
       "10                         Lyft, Inc.        11.0  0.658228   0.650000   \n",
       "11                          Snap Inc.        12.0  0.773050   0.807407   \n",
       "12            Spotify Technology S.A.        13.0  0.744444   0.779070   \n",
       "13                          AT&T Inc.        14.0  0.747029   0.774648   \n",
       "14                   T-Mobile US Inc.        15.0  0.761745   0.785467   \n",
       "15                 Sprint Corporation        16.0  0.694387   0.710638   \n",
       "16        Verizon Communications Inc.        17.0  0.670412   0.670412   \n",
       "17               JPMorgan Chase & Co.        18.0  0.696104   0.978102   \n",
       "18                     Citigroup Inc.        19.0  0.658635   0.976190   \n",
       "19                    Bank of America        20.0  0.668740   0.964126   \n",
       "20              Wells Fargo & Company        21.0  0.696721   0.934066   \n",
       "21              PayPal Holdings, Inc.        27.0  0.744283   0.778261   \n",
       "22       The American Express Company        28.0  0.689560   0.909420   \n",
       "23  Capital One Financial Corporation        30.0  0.682422   0.885057   \n",
       "24                      Netflix, Inc.        31.0  0.721612   0.740602   \n",
       "25           DISH Network Corporation        32.0  0.657609   0.927203   \n",
       "26                Comcast Corporation        33.0  0.669131   0.660584   \n",
       "27                     ViacomCBS Inc.        34.0  0.650104   0.630522   \n",
       "28                    Fox Corporation        35.0  0.833333   0.853659   \n",
       "29                       Grubhub Inc.       121.0  0.777778   0.777778   \n",
       "\n",
       "      recall  accuracy  \n",
       "0   0.692000  0.666016  \n",
       "1   0.714286  0.691406  \n",
       "2   0.730909  0.705078  \n",
       "3   0.710623  0.699219  \n",
       "4   0.676259  0.652344  \n",
       "5   0.714801  0.722656  \n",
       "6   0.706827  0.701172  \n",
       "7   0.524838  0.529297  \n",
       "8   0.743961  0.729970  \n",
       "9   0.720930  0.698795  \n",
       "10  0.666667  0.674699  \n",
       "11  0.741497  0.752896  \n",
       "12  0.712766  0.724551  \n",
       "13  0.721311  0.708984  \n",
       "14  0.739414  0.722656  \n",
       "15  0.678862  0.712891  \n",
       "16  0.670412  0.656250  \n",
       "17  0.540323  0.542969  \n",
       "18  0.496970  0.501953  \n",
       "19  0.511905  0.520270  \n",
       "20  0.555556  0.564706  \n",
       "21  0.713147  0.711944  \n",
       "22  0.555310  0.558594  \n",
       "23  0.555288  0.580078  \n",
       "24  0.703571  0.703125  \n",
       "25  0.509474  0.507812  \n",
       "26  0.677903  0.650391  \n",
       "27  0.670940  0.669922  \n",
       "28  0.813953  0.831325  \n",
       "29  0.777778  0.759036  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#see performance of Random Forest by company\n",
    "#each row shows : (company id, f1, precision, recall, accuracy)\n",
    "rf_df = pd.DataFrame(rf_company_results, columns = ['company_id', 'f1', 'precision', 'recall', 'accuracy'])\n",
    "companies_df[['id', 'name']].merge(rf_df, left_on='id', right_on='company_id').drop(columns ='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create array of performance metrics of logistic regression by company\n",
    "lg_company_results = np.zeros((30, 5))\n",
    "full_df = make_dataframes(reddit_df, lookback = 15, min_date = '2014-03-01')[0]\n",
    "full_df = full_df[full_df.num_posts >0]\n",
    "X = full_df[['avg_weighted_compound', 'avg_weighted_positive', 'avg_weighted_negative', 'avg_weighted_neutral', 'num_posts', 'avg_positive_posts', 'avg_negative_posts']]\n",
    "y = full_df['change_percent'] > 0\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.2, random_state = 6240)\n",
    "lg = LogisticRegression()\n",
    "lg.fit(X_train, y_train)\n",
    "preds = lg.predict(X_test)\n",
    "f1 = f1_score(preds, y_test)\n",
    "precision = precision_score(preds, y_test)\n",
    "recall = recall_score(preds, y_test)\n",
    "accuracy = accuracy_score(preds, y_test)\n",
    "dfs = make_dataframes(reddit_df, 'company', lookback = i, min_date = '2014-03-01')\n",
    "i=0\n",
    "for df in dfs:\n",
    "    c_id = df.company_id[0]\n",
    "    X = df[['avg_weighted_compound', 'avg_weighted_positive', 'avg_weighted_negative', 'avg_weighted_neutral', 'num_posts', 'avg_positive_posts', 'avg_negative_posts']]\n",
    "    y = df['change_percent'] > 0\n",
    "    preds = lg.predict(X)\n",
    "    f1 = f1_score(preds, y)\n",
    "    precision = precision_score(preds, y)\n",
    "    recall = recall_score(preds, y)\n",
    "    accuracy = accuracy_score(preds, y)\n",
    "    lg_company_results[i,] = [c_id, f1, precision, recall, accuracy]\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>company_id</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Microsoft Corporation</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.685494</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.521484</td>\n",
       "      <td>0.521484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.693878</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.531250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazon.com, Inc.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.703797</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.542969</td>\n",
       "      <td>0.542969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Facebook, Inc.</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.688860</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.525391</td>\n",
       "      <td>0.525391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alphabet Inc</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.700508</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.539062</td>\n",
       "      <td>0.539062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>eBay Inc.</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.675291</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.509766</td>\n",
       "      <td>0.509766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Twitter, Inc.</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HP Inc.</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.680412</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>0.515625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dell Technologies Inc.</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.725898</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.569733</td>\n",
       "      <td>0.569733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Uber Technologies, Inc.</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.692913</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.530120</td>\n",
       "      <td>0.530120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Lyft, Inc.</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.650407</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.481928</td>\n",
       "      <td>0.481928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Snap Inc.</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.685279</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.521236</td>\n",
       "      <td>0.521236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Spotify Technology S.A.</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.679842</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.514970</td>\n",
       "      <td>0.514970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AT&amp;T Inc.</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.713568</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.554688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>T-Mobile US Inc.</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.721598</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.564453</td>\n",
       "      <td>0.564453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Sprint Corporation</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.629183</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.458984</td>\n",
       "      <td>0.458984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Verizon Communications Inc.</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.685494</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.521484</td>\n",
       "      <td>0.521484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>JPMorgan Chase &amp; Co.</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.697201</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.535156</td>\n",
       "      <td>0.535156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Citigroup Inc.</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.659686</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.492188</td>\n",
       "      <td>0.492188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Bank of America</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.668666</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.502252</td>\n",
       "      <td>0.502252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Wells Fargo &amp; Company</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.697318</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.535294</td>\n",
       "      <td>0.535294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PayPal Holdings, Inc.</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.700152</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.538642</td>\n",
       "      <td>0.538642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>The American Express Company</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.700508</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.539062</td>\n",
       "      <td>0.539062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Capital One Financial Corporation</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.675291</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.509766</td>\n",
       "      <td>0.509766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Netflix, Inc.</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.683805</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.519531</td>\n",
       "      <td>0.519531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>DISH Network Corporation</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.675291</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.509766</td>\n",
       "      <td>0.509766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Comcast Corporation</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.697201</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.535156</td>\n",
       "      <td>0.535156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ViacomCBS Inc.</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.654402</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.486328</td>\n",
       "      <td>0.486328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Fox Corporation</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.493976</td>\n",
       "      <td>0.493976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Grubhub Inc.</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.542169</td>\n",
       "      <td>0.542169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 name  company_id        f1  precision  \\\n",
       "0               Microsoft Corporation         1.0  0.685494        1.0   \n",
       "1                          Apple Inc.         2.0  0.693878        1.0   \n",
       "2                    Amazon.com, Inc.         3.0  0.703797        1.0   \n",
       "3                      Facebook, Inc.         4.0  0.688860        1.0   \n",
       "4                        Alphabet Inc         5.0  0.700508        1.0   \n",
       "5                           eBay Inc.         6.0  0.675291        1.0   \n",
       "6                       Twitter, Inc.         7.0  0.666667        1.0   \n",
       "7                             HP Inc.         8.0  0.680412        1.0   \n",
       "8              Dell Technologies Inc.         9.0  0.725898        1.0   \n",
       "9             Uber Technologies, Inc.        10.0  0.692913        1.0   \n",
       "10                         Lyft, Inc.        11.0  0.650407        1.0   \n",
       "11                          Snap Inc.        12.0  0.685279        1.0   \n",
       "12            Spotify Technology S.A.        13.0  0.679842        1.0   \n",
       "13                          AT&T Inc.        14.0  0.713568        1.0   \n",
       "14                   T-Mobile US Inc.        15.0  0.721598        1.0   \n",
       "15                 Sprint Corporation        16.0  0.629183        1.0   \n",
       "16        Verizon Communications Inc.        17.0  0.685494        1.0   \n",
       "17               JPMorgan Chase & Co.        18.0  0.697201        1.0   \n",
       "18                     Citigroup Inc.        19.0  0.659686        1.0   \n",
       "19                    Bank of America        20.0  0.668666        1.0   \n",
       "20              Wells Fargo & Company        21.0  0.697318        1.0   \n",
       "21              PayPal Holdings, Inc.        27.0  0.700152        1.0   \n",
       "22       The American Express Company        28.0  0.700508        1.0   \n",
       "23  Capital One Financial Corporation        30.0  0.675291        1.0   \n",
       "24                      Netflix, Inc.        31.0  0.683805        1.0   \n",
       "25           DISH Network Corporation        32.0  0.675291        1.0   \n",
       "26                Comcast Corporation        33.0  0.697201        1.0   \n",
       "27                     ViacomCBS Inc.        34.0  0.654402        1.0   \n",
       "28                    Fox Corporation        35.0  0.661290        1.0   \n",
       "29                       Grubhub Inc.       121.0  0.703125        1.0   \n",
       "\n",
       "      recall  accuracy  \n",
       "0   0.521484  0.521484  \n",
       "1   0.531250  0.531250  \n",
       "2   0.542969  0.542969  \n",
       "3   0.525391  0.525391  \n",
       "4   0.539062  0.539062  \n",
       "5   0.509766  0.509766  \n",
       "6   0.500000  0.500000  \n",
       "7   0.515625  0.515625  \n",
       "8   0.569733  0.569733  \n",
       "9   0.530120  0.530120  \n",
       "10  0.481928  0.481928  \n",
       "11  0.521236  0.521236  \n",
       "12  0.514970  0.514970  \n",
       "13  0.554688  0.554688  \n",
       "14  0.564453  0.564453  \n",
       "15  0.458984  0.458984  \n",
       "16  0.521484  0.521484  \n",
       "17  0.535156  0.535156  \n",
       "18  0.492188  0.492188  \n",
       "19  0.502252  0.502252  \n",
       "20  0.535294  0.535294  \n",
       "21  0.538642  0.538642  \n",
       "22  0.539062  0.539062  \n",
       "23  0.509766  0.509766  \n",
       "24  0.519531  0.519531  \n",
       "25  0.509766  0.509766  \n",
       "26  0.535156  0.535156  \n",
       "27  0.486328  0.486328  \n",
       "28  0.493976  0.493976  \n",
       "29  0.542169  0.542169  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#see logistic regression results by company\n",
    "lg_df = pd.DataFrame(lg_company_results, columns = ['company_id', 'f1', 'precision', 'recall', 'accuracy'])\n",
    "companies_df[['id', 'name']].merge(lg_df, left_on='id', right_on='company_id').drop(columns ='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall scores: f1:0.628087986463621, precision: 0.7347585114806018, recall:0.5484633569739953, accuracy0.5327380952380952\n"
     ]
    }
   ],
   "source": [
    "#gradient boost\n",
    "xg_company_results = np.zeros((30, 5))\n",
    "full_df = make_dataframes(reddit_df, lookback = 28, min_date = '2014-03-01')[0]\n",
    "full_df = full_df[full_df.num_posts >0]\n",
    "X = full_df[['avg_weighted_compound', 'avg_weighted_positive', 'avg_weighted_negative', 'avg_weighted_neutral', 'num_posts', 'avg_positive_posts', 'avg_negative_posts']]\n",
    "y = full_df['change_percent'] > 0\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.25, random_state = 6240)\n",
    "xg = GradientBoostingClassifier(n_estimators= 100)\n",
    "xg.fit(X_train, y_train)\n",
    "preds = xg.predict(X_test)\n",
    "f1 = f1_score(preds, y_test)\n",
    "precision = precision_score(preds, y_test)\n",
    "recall = recall_score(preds, y_test)\n",
    "accuracy = accuracy_score(preds, y_test)\n",
    "dfs = make_dataframes(reddit_df, 'company', lookback = i, min_date = '2014-03-01')\n",
    "print('overall scores: f1:{0}, precision: {1}, recall:{2}, accuracy{3}'.format(f1, precision, recall, accuracy))\n",
    "i=0\n",
    "for df in dfs:\n",
    "    c_id = df.company_id[0]\n",
    "    X = df[['avg_weighted_compound', 'avg_weighted_positive', 'avg_weighted_negative', 'avg_weighted_neutral', 'num_posts', 'avg_positive_posts', 'avg_negative_posts']]\n",
    "    y = df['change_percent'] > 0\n",
    "    preds = xg.predict(X)\n",
    "    f1 = f1_score(preds, y)\n",
    "    precision = precision_score(preds, y)\n",
    "    recall = recall_score(preds, y)\n",
    "    accuracy = accuracy_score(preds, y)\n",
    "    xg_company_results[i,] = [c_id, f1, precision, recall, accuracy]\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>company_id</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Microsoft Corporation</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.663717</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.547445</td>\n",
       "      <td>0.554688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.672439</td>\n",
       "      <td>0.856618</td>\n",
       "      <td>0.553444</td>\n",
       "      <td>0.556641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazon.com, Inc.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.691892</td>\n",
       "      <td>0.920863</td>\n",
       "      <td>0.554113</td>\n",
       "      <td>0.554688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Facebook, Inc.</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.677551</td>\n",
       "      <td>0.925651</td>\n",
       "      <td>0.534335</td>\n",
       "      <td>0.537109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alphabet Inc</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.674253</td>\n",
       "      <td>0.858696</td>\n",
       "      <td>0.555035</td>\n",
       "      <td>0.552734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>eBay Inc.</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.599315</td>\n",
       "      <td>0.670498</td>\n",
       "      <td>0.541796</td>\n",
       "      <td>0.542969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Twitter, Inc.</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.543651</td>\n",
       "      <td>0.535156</td>\n",
       "      <td>0.552419</td>\n",
       "      <td>0.550781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HP Inc.</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.671159</td>\n",
       "      <td>0.943182</td>\n",
       "      <td>0.520921</td>\n",
       "      <td>0.523438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dell Technologies Inc.</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.719682</td>\n",
       "      <td>0.942708</td>\n",
       "      <td>0.581994</td>\n",
       "      <td>0.581602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Uber Technologies, Inc.</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.626263</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>0.563636</td>\n",
       "      <td>0.554217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Lyft, Inc.</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.457831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Snap Inc.</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.681199</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.538793</td>\n",
       "      <td>0.548263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Spotify Technology S.A.</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.698113</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.587302</td>\n",
       "      <td>0.616766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AT&amp;T Inc.</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.642968</td>\n",
       "      <td>0.732394</td>\n",
       "      <td>0.573003</td>\n",
       "      <td>0.548828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>T-Mobile US Inc.</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.702624</td>\n",
       "      <td>0.833910</td>\n",
       "      <td>0.607053</td>\n",
       "      <td>0.601562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Sprint Corporation</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.483370</td>\n",
       "      <td>0.463830</td>\n",
       "      <td>0.504630</td>\n",
       "      <td>0.544922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Verizon Communications Inc.</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.629690</td>\n",
       "      <td>0.722846</td>\n",
       "      <td>0.557803</td>\n",
       "      <td>0.556641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>JPMorgan Chase &amp; Co.</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.696891</td>\n",
       "      <td>0.981752</td>\n",
       "      <td>0.540161</td>\n",
       "      <td>0.542969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Citigroup Inc.</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.659489</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.498982</td>\n",
       "      <td>0.505859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Bank of America</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.661392</td>\n",
       "      <td>0.937220</td>\n",
       "      <td>0.511002</td>\n",
       "      <td>0.518018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Wells Fargo &amp; Company</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.696721</td>\n",
       "      <td>0.934066</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.564706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PayPal Holdings, Inc.</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.707741</td>\n",
       "      <td>0.973913</td>\n",
       "      <td>0.555831</td>\n",
       "      <td>0.566745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>The American Express Company</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.691257</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.554825</td>\n",
       "      <td>0.558594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Capital One Financial Corporation</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.669565</td>\n",
       "      <td>0.885057</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.554688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Netflix, Inc.</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.674385</td>\n",
       "      <td>0.875940</td>\n",
       "      <td>0.548235</td>\n",
       "      <td>0.560547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>DISH Network Corporation</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.659401</td>\n",
       "      <td>0.927203</td>\n",
       "      <td>0.511628</td>\n",
       "      <td>0.511719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Comcast Corporation</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.604341</td>\n",
       "      <td>0.660584</td>\n",
       "      <td>0.556923</td>\n",
       "      <td>0.537109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ViacomCBS Inc.</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.556263</td>\n",
       "      <td>0.526104</td>\n",
       "      <td>0.590090</td>\n",
       "      <td>0.591797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Fox Corporation</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.817204</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.795181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Grubhub Inc.</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.678899</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>0.578313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 name  company_id        f1  precision  \\\n",
       "0               Microsoft Corporation         1.0  0.663717   0.842697   \n",
       "1                          Apple Inc.         2.0  0.672439   0.856618   \n",
       "2                    Amazon.com, Inc.         3.0  0.691892   0.920863   \n",
       "3                      Facebook, Inc.         4.0  0.677551   0.925651   \n",
       "4                        Alphabet Inc         5.0  0.674253   0.858696   \n",
       "5                           eBay Inc.         6.0  0.599315   0.670498   \n",
       "6                       Twitter, Inc.         7.0  0.543651   0.535156   \n",
       "7                             HP Inc.         8.0  0.671159   0.943182   \n",
       "8              Dell Technologies Inc.         9.0  0.719682   0.942708   \n",
       "9             Uber Technologies, Inc.        10.0  0.626263   0.704545   \n",
       "10                         Lyft, Inc.        11.0  0.470588   0.500000   \n",
       "11                          Snap Inc.        12.0  0.681199   0.925926   \n",
       "12            Spotify Technology S.A.        13.0  0.698113   0.860465   \n",
       "13                          AT&T Inc.        14.0  0.642968   0.732394   \n",
       "14                   T-Mobile US Inc.        15.0  0.702624   0.833910   \n",
       "15                 Sprint Corporation        16.0  0.483370   0.463830   \n",
       "16        Verizon Communications Inc.        17.0  0.629690   0.722846   \n",
       "17               JPMorgan Chase & Co.        18.0  0.696891   0.981752   \n",
       "18                     Citigroup Inc.        19.0  0.659489   0.972222   \n",
       "19                    Bank of America        20.0  0.661392   0.937220   \n",
       "20              Wells Fargo & Company        21.0  0.696721   0.934066   \n",
       "21              PayPal Holdings, Inc.        27.0  0.707741   0.973913   \n",
       "22       The American Express Company        28.0  0.691257   0.916667   \n",
       "23  Capital One Financial Corporation        30.0  0.669565   0.885057   \n",
       "24                      Netflix, Inc.        31.0  0.674385   0.875940   \n",
       "25           DISH Network Corporation        32.0  0.659401   0.927203   \n",
       "26                Comcast Corporation        33.0  0.604341   0.660584   \n",
       "27                     ViacomCBS Inc.        34.0  0.556263   0.526104   \n",
       "28                    Fox Corporation        35.0  0.817204   0.926829   \n",
       "29                       Grubhub Inc.       121.0  0.678899   0.822222   \n",
       "\n",
       "      recall  accuracy  \n",
       "0   0.547445  0.554688  \n",
       "1   0.553444  0.556641  \n",
       "2   0.554113  0.554688  \n",
       "3   0.534335  0.537109  \n",
       "4   0.555035  0.552734  \n",
       "5   0.541796  0.542969  \n",
       "6   0.552419  0.550781  \n",
       "7   0.520921  0.523438  \n",
       "8   0.581994  0.581602  \n",
       "9   0.563636  0.554217  \n",
       "10  0.444444  0.457831  \n",
       "11  0.538793  0.548263  \n",
       "12  0.587302  0.616766  \n",
       "13  0.573003  0.548828  \n",
       "14  0.607053  0.601562  \n",
       "15  0.504630  0.544922  \n",
       "16  0.557803  0.556641  \n",
       "17  0.540161  0.542969  \n",
       "18  0.498982  0.505859  \n",
       "19  0.511002  0.518018  \n",
       "20  0.555556  0.564706  \n",
       "21  0.555831  0.566745  \n",
       "22  0.554825  0.558594  \n",
       "23  0.538462  0.554688  \n",
       "24  0.548235  0.560547  \n",
       "25  0.511628  0.511719  \n",
       "26  0.556923  0.537109  \n",
       "27  0.590090  0.591797  \n",
       "28  0.730769  0.795181  \n",
       "29  0.578125  0.578313  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#xg boost results by company\n",
    "xg_df = pd.DataFrame(xg_company_results, columns = ['company_id', 'f1', 'precision', 'recall', 'accuracy'])\n",
    "companies_df[['id', 'name']].merge(xg_df, left_on='id', right_on='company_id').drop(columns ='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear regression\n",
    "ln_company_results = np.zeros((30, 5))\n",
    "full_df = make_dataframes(reddit_df, lookback = i, min_date = '2014-03-01')[0]\n",
    "full_df = full_df[full_df.num_posts >0]\n",
    "X = full_df[['avg_weighted_compound', 'avg_weighted_positive', 'avg_weighted_negative', 'avg_weighted_neutral', 'num_posts', 'avg_positive_posts', 'avg_negative_posts']]\n",
    "y = full_df['change_percent']\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.25, random_state = 6240)\n",
    "ln = LinearRegression()\n",
    "ln.fit(X_train, y_train)\n",
    "preds = ln.predict(X_test) > 0\n",
    "f1 = f1_score(preds, y_test > 0)\n",
    "precision = precision_score(preds, y_test > 0)\n",
    "recall = recall_score(preds, y_test > 0)\n",
    "accuracy = accuracy_score(preds, y_test > 0)\n",
    "dfs = make_dataframes(reddit_df, 'company', lookback = i, min_date = '2014-03-01')\n",
    "i=0\n",
    "for df in dfs:\n",
    "    c_id = df.company_id[0]\n",
    "    X = df[['avg_weighted_compound', 'avg_weighted_positive', 'avg_weighted_negative', 'avg_weighted_neutral', 'num_posts', 'avg_positive_posts', 'avg_negative_posts']]\n",
    "    y = df['change_percent']\n",
    "    preds = ln.predict(X) > 0\n",
    "    f1 = f1_score(preds, y>0)\n",
    "    precision = precision_score(preds, y>0)\n",
    "    recall = recall_score(preds, y>0)\n",
    "    accuracy = accuracy_score(preds, y>0)\n",
    "    ln_company_results[i,] = [c_id, f1, precision, recall, accuracy]\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>company_id</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Microsoft Corporation</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.685494</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.521484</td>\n",
       "      <td>0.521484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.693878</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.531250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazon.com, Inc.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.703797</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.542969</td>\n",
       "      <td>0.542969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Facebook, Inc.</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.688860</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.525391</td>\n",
       "      <td>0.525391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alphabet Inc</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.700508</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.539062</td>\n",
       "      <td>0.539062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>eBay Inc.</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.672727</td>\n",
       "      <td>0.992337</td>\n",
       "      <td>0.508841</td>\n",
       "      <td>0.507812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Twitter, Inc.</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.669281</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.502947</td>\n",
       "      <td>0.505859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HP Inc.</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.672021</td>\n",
       "      <td>0.950758</td>\n",
       "      <td>0.519669</td>\n",
       "      <td>0.521484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dell Technologies Inc.</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.560748</td>\n",
       "      <td>0.545994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Uber Technologies, Inc.</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.698413</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.542169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Lyft, Inc.</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.650407</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.481928</td>\n",
       "      <td>0.481928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Snap Inc.</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.685279</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.521236</td>\n",
       "      <td>0.521236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Spotify Technology S.A.</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.679842</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.514970</td>\n",
       "      <td>0.514970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AT&amp;T Inc.</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.633431</td>\n",
       "      <td>0.760563</td>\n",
       "      <td>0.542714</td>\n",
       "      <td>0.511719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>T-Mobile US Inc.</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.611801</td>\n",
       "      <td>0.681661</td>\n",
       "      <td>0.554930</td>\n",
       "      <td>0.511719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Sprint Corporation</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.600316</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.477387</td>\n",
       "      <td>0.505859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Verizon Communications Inc.</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.617600</td>\n",
       "      <td>0.722846</td>\n",
       "      <td>0.539106</td>\n",
       "      <td>0.533203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>JPMorgan Chase &amp; Co.</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.697201</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.535156</td>\n",
       "      <td>0.535156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Citigroup Inc.</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.662286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.495088</td>\n",
       "      <td>0.498047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Bank of America</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.662519</td>\n",
       "      <td>0.955157</td>\n",
       "      <td>0.507143</td>\n",
       "      <td>0.511261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Wells Fargo &amp; Company</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.541176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PayPal Holdings, Inc.</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.700152</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.538642</td>\n",
       "      <td>0.538642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>The American Express Company</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.677732</td>\n",
       "      <td>0.887681</td>\n",
       "      <td>0.548098</td>\n",
       "      <td>0.544922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Capital One Financial Corporation</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.657224</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.521348</td>\n",
       "      <td>0.527344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Netflix, Inc.</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.681404</td>\n",
       "      <td>0.984962</td>\n",
       "      <td>0.520875</td>\n",
       "      <td>0.521484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>DISH Network Corporation</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.647696</td>\n",
       "      <td>0.915709</td>\n",
       "      <td>0.501048</td>\n",
       "      <td>0.492188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Comcast Corporation</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.668547</td>\n",
       "      <td>0.864964</td>\n",
       "      <td>0.544828</td>\n",
       "      <td>0.541016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ViacomCBS Inc.</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.602151</td>\n",
       "      <td>0.787149</td>\n",
       "      <td>0.487562</td>\n",
       "      <td>0.494141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Fox Corporation</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.493976</td>\n",
       "      <td>0.493976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Grubhub Inc.</td>\n",
       "      <td>121.0</td>\n",
       "      <td>0.703125</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.542169</td>\n",
       "      <td>0.542169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 name  company_id        f1  precision  \\\n",
       "0               Microsoft Corporation         1.0  0.685494   1.000000   \n",
       "1                          Apple Inc.         2.0  0.693878   1.000000   \n",
       "2                    Amazon.com, Inc.         3.0  0.703797   1.000000   \n",
       "3                      Facebook, Inc.         4.0  0.688860   1.000000   \n",
       "4                        Alphabet Inc         5.0  0.700508   1.000000   \n",
       "5                           eBay Inc.         6.0  0.672727   0.992337   \n",
       "6                       Twitter, Inc.         7.0  0.669281   1.000000   \n",
       "7                             HP Inc.         8.0  0.672021   0.950758   \n",
       "8              Dell Technologies Inc.         9.0  0.701754   0.937500   \n",
       "9             Uber Technologies, Inc.        10.0  0.698413   1.000000   \n",
       "10                         Lyft, Inc.        11.0  0.650407   1.000000   \n",
       "11                          Snap Inc.        12.0  0.685279   1.000000   \n",
       "12            Spotify Technology S.A.        13.0  0.679842   1.000000   \n",
       "13                          AT&T Inc.        14.0  0.633431   0.760563   \n",
       "14                   T-Mobile US Inc.        15.0  0.611801   0.681661   \n",
       "15                 Sprint Corporation        16.0  0.600316   0.808511   \n",
       "16        Verizon Communications Inc.        17.0  0.617600   0.722846   \n",
       "17               JPMorgan Chase & Co.        18.0  0.697201   1.000000   \n",
       "18                     Citigroup Inc.        19.0  0.662286   1.000000   \n",
       "19                    Bank of America        20.0  0.662519   0.955157   \n",
       "20              Wells Fargo & Company        21.0  0.700000   1.000000   \n",
       "21              PayPal Holdings, Inc.        27.0  0.700152   1.000000   \n",
       "22       The American Express Company        28.0  0.677732   0.887681   \n",
       "23  Capital One Financial Corporation        30.0  0.657224   0.888889   \n",
       "24                      Netflix, Inc.        31.0  0.681404   0.984962   \n",
       "25           DISH Network Corporation        32.0  0.647696   0.915709   \n",
       "26                Comcast Corporation        33.0  0.668547   0.864964   \n",
       "27                     ViacomCBS Inc.        34.0  0.602151   0.787149   \n",
       "28                    Fox Corporation        35.0  0.661290   1.000000   \n",
       "29                       Grubhub Inc.       121.0  0.703125   1.000000   \n",
       "\n",
       "      recall  accuracy  \n",
       "0   0.521484  0.521484  \n",
       "1   0.531250  0.531250  \n",
       "2   0.542969  0.542969  \n",
       "3   0.525391  0.525391  \n",
       "4   0.539062  0.539062  \n",
       "5   0.508841  0.507812  \n",
       "6   0.502947  0.505859  \n",
       "7   0.519669  0.521484  \n",
       "8   0.560748  0.545994  \n",
       "9   0.536585  0.542169  \n",
       "10  0.481928  0.481928  \n",
       "11  0.521236  0.521236  \n",
       "12  0.514970  0.514970  \n",
       "13  0.542714  0.511719  \n",
       "14  0.554930  0.511719  \n",
       "15  0.477387  0.505859  \n",
       "16  0.539106  0.533203  \n",
       "17  0.535156  0.535156  \n",
       "18  0.495088  0.498047  \n",
       "19  0.507143  0.511261  \n",
       "20  0.538462  0.541176  \n",
       "21  0.538642  0.538642  \n",
       "22  0.548098  0.544922  \n",
       "23  0.521348  0.527344  \n",
       "24  0.520875  0.521484  \n",
       "25  0.501048  0.492188  \n",
       "26  0.544828  0.541016  \n",
       "27  0.487562  0.494141  \n",
       "28  0.493976  0.493976  \n",
       "29  0.542169  0.542169  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ln_df = pd.DataFrame(ln_company_results, columns = ['company_id', 'f1', 'precision', 'recall', 'accuracy'])\n",
    "companies_df[['id', 'name']].merge(ln_df, left_on='id', right_on='company_id').drop(columns ='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>hq_city</th>\n",
       "      <th>hq_state</th>\n",
       "      <th>year_founded</th>\n",
       "      <th>year_ipo</th>\n",
       "      <th>industry_id</th>\n",
       "      <th>stock_ticker</th>\n",
       "      <th>stock_exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Microsoft Corporation</td>\n",
       "      <td>Redmond</td>\n",
       "      <td>WA</td>\n",
       "      <td>1975</td>\n",
       "      <td>1986</td>\n",
       "      <td>1</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>NASDAQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Apple Inc.</td>\n",
       "      <td>Cupertino</td>\n",
       "      <td>CA</td>\n",
       "      <td>1976</td>\n",
       "      <td>1980</td>\n",
       "      <td>1</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>NASDAQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Amazon.com, Inc.</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>1994</td>\n",
       "      <td>1997</td>\n",
       "      <td>1</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>NASDAQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Facebook, Inc.</td>\n",
       "      <td>Menlo Park</td>\n",
       "      <td>CA</td>\n",
       "      <td>2004</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>FB</td>\n",
       "      <td>NASDAQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Alphabet Inc</td>\n",
       "      <td>Mountain View</td>\n",
       "      <td>CA</td>\n",
       "      <td>1998</td>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>GOOGL</td>\n",
       "      <td>NASDAQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>118</td>\n",
       "      <td>Fiat Chrysler Automobiles</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>1899</td>\n",
       "      <td>2010</td>\n",
       "      <td>17</td>\n",
       "      <td>FCAU</td>\n",
       "      <td>NYSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>119</td>\n",
       "      <td>Honda Motor Co., Ltd.</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>Japan</td>\n",
       "      <td>1946</td>\n",
       "      <td>1977</td>\n",
       "      <td>17</td>\n",
       "      <td>HMC</td>\n",
       "      <td>NYSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>120</td>\n",
       "      <td>Toyota Motor Corporation</td>\n",
       "      <td>Toyota City</td>\n",
       "      <td>Japan</td>\n",
       "      <td>1937</td>\n",
       "      <td>1999</td>\n",
       "      <td>17</td>\n",
       "      <td>TM</td>\n",
       "      <td>NYSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>121</td>\n",
       "      <td>Grubhub Inc.</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>2004</td>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>GRUB</td>\n",
       "      <td>NYSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>122</td>\n",
       "      <td>Campbell Soup Company</td>\n",
       "      <td>Camden</td>\n",
       "      <td>NJ</td>\n",
       "      <td>1869</td>\n",
       "      <td>1954</td>\n",
       "      <td>9</td>\n",
       "      <td>CPB</td>\n",
       "      <td>NYSE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                       name        hq_city     hq_state  year_founded  \\\n",
       "0      1      Microsoft Corporation        Redmond           WA          1975   \n",
       "1      2                 Apple Inc.      Cupertino           CA          1976   \n",
       "2      3           Amazon.com, Inc.        Seattle           WA          1994   \n",
       "3      4             Facebook, Inc.     Menlo Park           CA          2004   \n",
       "4      5               Alphabet Inc  Mountain View           CA          1998   \n",
       "..   ...                        ...            ...          ...           ...   \n",
       "117  118  Fiat Chrysler Automobiles      Amsterdam  Netherlands          1899   \n",
       "118  119      Honda Motor Co., Ltd.          Tokyo        Japan          1946   \n",
       "119  120   Toyota Motor Corporation    Toyota City        Japan          1937   \n",
       "120  121               Grubhub Inc.        Chicago           IL          2004   \n",
       "121  122      Campbell Soup Company         Camden           NJ          1869   \n",
       "\n",
       "     year_ipo  industry_id stock_ticker stock_exchange  \n",
       "0        1986            1         MSFT         NASDAQ  \n",
       "1        1980            1         AAPL         NASDAQ  \n",
       "2        1997            1         AMZN         NASDAQ  \n",
       "3        2012            1           FB         NASDAQ  \n",
       "4        2004            1        GOOGL         NASDAQ  \n",
       "..        ...          ...          ...            ...  \n",
       "117      2010           17         FCAU           NYSE  \n",
       "118      1977           17          HMC           NYSE  \n",
       "119      1999           17           TM           NYSE  \n",
       "120      2014            1         GRUB           NYSE  \n",
       "121      1954            9          CPB           NYSE  \n",
       "\n",
       "[122 rows x 9 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
